\chapter{方法介绍}\label{sec:method}
\section{前言}
随着深度学习渗透到医学影像分析领域的方方面面，生物标记物定位任务也受到研究者的持续关注，其性能也在稳步提升。然而正如\ref{subsec:related_work_summary}小结所描述的，由于目前已有方法由于自身原因无法精确定位生物标记物位置，因而无法达到令人满意的性能。

有鉴于此，本文将提出一种全新的网络模型和训练方法，以期达到精确定位生物标记物的目的。本章将介绍本文针对精确生物标记物定位任务而提出的网络模型和训练方法。具体而言，在\ref{sec:idea_thinking}小节，本文将解释我们的对于此问题的思考，以期读者能更好地理解我们的模型。接着，在\ref{sec:model_architecture}小节中，本文将介绍模型结构，包括各个子模块（CNN分类器、判别器和编码器-解码器）和各自充当的角色及其作用。随后，我们将在\ref{sec:loss_func_training_stragies}小节中定义模型的损失函数，以及具体的网络更新策略（包括训练步骤及其对应损失函数）。最后，我们将对本章内容进行小结（见\ref{sec:chapter3_summary}小节），并引出下一章节将要阐述的主要内容。下面将具体阐述本章节的相关内容。
\section{解决思路}\label{sec:idea_thinking}
面对弱监督条件下，生物标记物的精确定位这一问题，鉴于已有方法只能粗略定位到生物标记物，我们最先想到用图像生成即对抗生成网络的思路去做，并且输入输出图像尺寸相等，这样就避免了CAM和Grad-CAM中由于上采样所造成的定位不精确的问题（相关解释参见\ref{subsec:related_work_summary}小节）。如果用映射$\mathcal{H}$来表示生成器，给定输入图片$I^{h\times w\times d}$（图像的高、宽和深度分为为$h$，$w$，$d$），则$\mathcal{H}$是一个图像到图像的映射，可形式化为：
\begin{equation*}
\mathcal{H}: I \to I'.
\end{equation*}
其中$I'^{h\times w\times d}$与$I$一样，均表示一张图像。假设生成器有识别生物标记物或者说患病区域的能力，不难想象，在理想状态下，给定输入图像$I$，生成器给出其输出图像$I'$，根据输入图像类别是正常还是异常，有以下推断：

\noindent 1）如果输入图像$I$是正常图像，则可认为输出图像$I'$与输入图像$I$一致，即此时输入图像并没有像素强度发生改变。

\noindent 2）如果输入图像$I$是异常图像，可以想象，与输出图像$I'$相比，输入图像$I$中只有极少数像素强度发生改变，而绝大部分像素强度没有发生改变，那么我们完全有理由认为这些发生改变了的像素便是生物标记物，此时我们可以认为输出图像$I'$是异常输入图像$I$去除生物标记物的“正常”版本，且生物标记物的准确位置$Y$为：
\begin{equation}\label{equ:idea}
Y=|I'-I|=|\mathcal{H}(I) - I|.
\end{equation}
\noindent 根据等式\ref{equ:idea}，一旦得到这样的生成器，便可以实现生物标记物的精确定位。根据以上设计，可知生成器满足以下两个条件：

\noindent 1）给定输入图像$I$，生成器能生成具有相同大小的输出图像$I'$。

\noindent 2）生成器具有良好的识别生物标记物的能力。

\noindent 对于条件一，实现比较容易，全卷积网络或者编码器-解码器，都能满足这一条件。考虑到近些年来编码器-解码器在图像生成领域所取得的巨大成就，我们优先考虑选择编码器-解码器。主要难点在于第二点：如何让编码器-解码器具备识别生物标记物或者说异常信号的能力。编码器-解码器作为一种无监督模型，最朴素的想法是只使用正常图像训练编码器-解码器，使其具有重建正常图像或者说正常信号的能力，当送入异常图像时，由于编码器-解码器并未见过异常信号，故编码器-解码器无法较好重建异常信号，从而间接使编码器-解码器具有识别异常信号的能力。实际上，在单张图像中，由于生物标记物所占的像素在整张图像中只占很小一部分（$\le 2\%$），再加上CNN强大的拟合能力和高容量，这种位于局部的图像细节差异往往非常不明显，很难被凸显出来。

考虑到对抗生成网络与编码器-解码器的结合并能有效处理图像中小部分遮挡物的去除问题，如Qian等人~\cite{qian2018attentive}在单张图像中去除雨滴 Yuan等人~\cite{yuan2019face}去除脸中遮挡物

\section{模型结构}\label{sec:model_architecture}
\section{损失函数与训练策略}\label{sec:loss_func_training_stragies}
\begin{algorithm}[h]
	\SetAlgoLined
	\caption{本文提出的网络结构的优化过程}
	\label{alg:net}
	%\KwIn{Sample normal images $x\in \mathbb{P}_n$, lesion images $z\in \mathbb{P}_l$.}
	%\KwOut{$y$, the net activation}
	%$y\leftarrow 0$\;
	\SetKwInOut{Input}{Input}\SetKwInOut{Output}{output}
	\Input{learning rate $\alpha$, batch size $m$, hyperparameters $\lambda _1$ and $\lambda _2$, encoder-decoder's parameters $\theta _g$, classifier's parameters $\theta _c$, discriminator's parameters $\theta _d$, maximum iterations $K$.}
	\nl \For{$k\leftarrow 1$ \KwTo $K$}{
		%reference: http://mlg.ulb.ac.be/files/algorithm2e.pdf
		\nl
		Sample a batch $\{x^{(i)}\}_{i=1}^{m}$ from the normal dataset, and a batch $\{z^{(i)}\}_{i=1}^{m}$ from the abnormal dataset; collect both to get batch $y=\{y^{(i)}\}_{i=1}^{2m}$.\\
		\nl	$L_{u\_c}$ $\leftarrow \lambda _1$[$\frac{1}{2m}\sum_{i=1}^{2m}$$L_{CE}(C, G(y^{(i)}))$] + $\lambda _2[\frac{1}{2m}\sum_{i=1}^{2m}L_{ED}G(y^{(i)})]$  \\
		\nl	$\theta _g$$\leftarrow Adam(\nabla _{\theta _g}  L_{u\_c}, \theta _g, \alpha)$ 
		\tcp*{minimize G}
		\nl	$\theta _c$$\leftarrow Adam(\nabla _{\theta _c} L_{u\_c}, \theta _c, \alpha)$  
		\tcp*{minimize C}
		\nl	$L_{u\_d}$ $\leftarrow $$\frac{1}{m}\sum_{i=1}^{m}$$L_{GAN}(D(G(z^{(i)}))-D(x^{(i)}))$ + $\lambda _2[\frac{1}{2m}\sum_{i=1}^{2m}L_{ED}(G(y^{(i)}))]$  \\
		\nl	$\theta _d$$\leftarrow -Adam(\nabla _{\theta _d} L_{u\_d}, \theta _d, \alpha)$ 
		\tcp*{maximize D}
		\nl	$\theta _g$$\leftarrow Adam(\nabla _{\theta _g} L_{u\_d}, \theta _g, \alpha)$ 
		\tcp*{minimize G}
	}
\end{algorithm}

\section{本章小结}\label{sec:chapter3_summary}

